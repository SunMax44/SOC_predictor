{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ed1a7355-bb4d-4241-9a46-94b7f65dfd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system:index</th>\n",
       "      <th>BSI</th>\n",
       "      <th>NDMI</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>SOCI</th>\n",
       "      <th>sample_date</th>\n",
       "      <th>.geo</th>\n",
       "      <th>quarter</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.020134</td>\n",
       "      <td>0.071468</td>\n",
       "      <td>0.085867</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>2018-12-20</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[22.72922449,45....</td>\n",
       "      <td>2018_Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.001685</td>\n",
       "      <td>0.063842</td>\n",
       "      <td>0.098104</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[28.198854880000...</td>\n",
       "      <td>2018_Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.115698</td>\n",
       "      <td>0.341321</td>\n",
       "      <td>0.018842</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[28.333738630000...</td>\n",
       "      <td>2018_Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.094990</td>\n",
       "      <td>0.273026</td>\n",
       "      <td>0.047869</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[23.314151240000...</td>\n",
       "      <td>2018_Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.078319</td>\n",
       "      <td>0.130311</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[28.181462420000...</td>\n",
       "      <td>2018_Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   system:index       BSI      NDMI      NDVI      SOCI sample_date  \\\n",
       "0             0 -0.020134  0.071468  0.085867  0.000069  2018-12-20   \n",
       "1             1 -0.001685  0.063842  0.098104  0.000061  2018-12-19   \n",
       "2             2 -0.115698  0.341321  0.018842  0.000051  2018-12-19   \n",
       "3             3 -0.094990  0.273026  0.047869  0.000056  2018-12-19   \n",
       "4             4  0.011718  0.078319  0.130311  0.000064  2018-12-19   \n",
       "\n",
       "                                                .geo  quarter  lat  long  \n",
       "0  {\"type\":\"Point\",\"coordinates\":[22.72922449,45....  2018_Q1  NaN   NaN  \n",
       "1  {\"type\":\"Point\",\"coordinates\":[28.198854880000...  2018_Q1  NaN   NaN  \n",
       "2  {\"type\":\"Point\",\"coordinates\":[28.333738630000...  2018_Q1  NaN   NaN  \n",
       "3  {\"type\":\"Point\",\"coordinates\":[23.314151240000...  2018_Q1  NaN   NaN  \n",
       "4  {\"type\":\"Point\",\"coordinates\":[28.181462420000...  2018_Q1  NaN   NaN  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Directory where the CSV files are located\n",
    "csv_dir = '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices'  # Replace with your path\n",
    "\n",
    "# List to store all dataframes\n",
    "df_list = []\n",
    "\n",
    "# Function to extract the identifier from the filename\n",
    "def extract_identifier(filename):\n",
    "    base_name = os.path.basename(filename).replace('.csv', '')  # Remove the .csv extension\n",
    "    year = base_name.split('_')[-2]\n",
    "    month = int(base_name.split('_')[-1])  # Convert month directly to int\n",
    "    quarter = (month - 1) // 3 + 1  # Calculate the quarter\n",
    "    return f\"{year}_Q{quarter}\"\n",
    "\n",
    "# Read all CSV files, add the identifier column, and append to the list\n",
    "for file in glob.glob(os.path.join(csv_dir, '*.csv')):\n",
    "    df = pd.read_csv(file)\n",
    "    df['quarter'] = extract_identifier(file)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "final_df = pd.concat(df_list, axis=0, join='outer', ignore_index=True)\n",
    "\n",
    "# Display the structure of the final DataFrame\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a19b026d-ed60-43f0-963e-73a937c64e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure .geo column is treated as a string and remove any extra whitespace\n",
    "final_df['.geo'] = final_df['.geo'].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6027dc3f-2dec-4200-b645-4cb24f9ed416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique location counts per file:\n",
      "{'/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2018_01.csv': 10931, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2016_10.csv': 10931, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2016_04.csv': 10931, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2014_01.csv': 18984, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2016_07.csv': 18984, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2018_07.csv': 10931, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2014_07.csv': 18984, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2016_01.csv': 10931, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2018_04.csv': 10931, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2018_10.csv': 10931, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2014_10.csv': 18984, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2014_04.csv': 18984, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2017_07.csv': 10931, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2017_04.csv': 10931, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2017_10.csv': 10931, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2015_01.csv': 10931, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2017_01.csv': 10931, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2015_04.csv': 10931, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2015_10.csv': 10931, '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2015_07.csv': 10931}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store unique locations per file\n",
    "location_counts = {}\n",
    "\n",
    "# Check unique locations in each file\n",
    "for file in glob.glob(os.path.join(csv_dir, '*.csv')):\n",
    "    df = pd.read_csv(file)\n",
    "    unique_locs = df['.geo'].astype(str).nunique()  # Unique locations in this file\n",
    "    location_counts[file] = unique_locs\n",
    "\n",
    "# Display the unique location count per file to find discrepancies\n",
    "print(\"Unique location counts per file:\")\n",
    "print(location_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "aa1b4507-db99-4e1c-9cfc-511ead9ccfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard number of unique locations: 10931\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load one of the correctly formatted files to get the standard 10,931 locations\n",
    "reference_file = '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2018_01.csv'\n",
    "reference_df = pd.read_csv(reference_file)\n",
    "reference_df['.geo'] = reference_df['.geo'].astype(str).str.strip()  # Standardize `.geo` values\n",
    "standard_locations = set(reference_df['.geo'].unique())\n",
    "\n",
    "print(f\"Standard number of unique locations: {len(standard_locations)}\")  # Should be 10,931\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "564a9288-8ebf-4e89-b861-24c4d952f45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2014_01.csv: 10931 unique locations (after filtering)\n",
      "/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2014_04.csv: 10931 unique locations (after filtering)\n",
      "/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2014_07.csv: 10931 unique locations (after filtering)\n",
      "/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2014_10.csv: 10931 unique locations (after filtering)\n",
      "/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2016_07.csv: 9893 unique locations (after filtering)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List of affected files with extra locations\n",
    "affected_files = [\n",
    "    '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2014_01.csv',\n",
    "    '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2014_04.csv',\n",
    "    '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2014_07.csv',\n",
    "    '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2014_10.csv',\n",
    "    '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2016_07.csv'\n",
    "]\n",
    "\n",
    "# Process each affected file\n",
    "for file in affected_files:\n",
    "    # Load the file and standardize `.geo` values\n",
    "    df = pd.read_csv(file)\n",
    "    df['.geo'] = df['.geo'].astype(str).str.strip()\n",
    "    \n",
    "    # Filter to keep only standard locations\n",
    "    df_filtered = df[df['.geo'].isin(standard_locations)]\n",
    "    \n",
    "    # Save the filtered data back to a new CSV file\n",
    "    output_file = os.path.join('/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/filtered', os.path.basename(file))\n",
    "    df_filtered.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Confirm the number of unique locations after filtering\n",
    "    print(f\"{file}: {df_filtered['.geo'].nunique()} unique locations (after filtering)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4c327c65-e39c-4188-a27e-47980441fcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: output_all_locations_2014_01.csv has no duplicates.\n",
      "\n",
      "File: output_all_locations_2014_04.csv has no duplicates.\n",
      "\n",
      "File: output_all_locations_2014_07.csv has no duplicates.\n",
      "\n",
      "File: output_all_locations_2014_10.csv has no duplicates.\n",
      "\n",
      "File: output_all_locations_2016_07.csv has no duplicates.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Directory where the CSV files are located\n",
    "csv_dir = '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices' \n",
    "\n",
    "# List of files with higher-than-expected unique locations\n",
    "affected_files = [\n",
    "    'output_all_locations_2014_01.csv',\n",
    "    'output_all_locations_2014_04.csv',\n",
    "    'output_all_locations_2014_07.csv',\n",
    "    'output_all_locations_2014_10.csv',\n",
    "    'output_all_locations_2016_07.csv'\n",
    "]\n",
    "\n",
    "# Check for duplicates in each affected file\n",
    "for file_name in affected_files:\n",
    "    file_path = os.path.join(csv_dir, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Standardize `.geo` values\n",
    "    df['.geo'] = df['.geo'].astype(str).str.strip()\n",
    "    \n",
    "    # Find duplicate `.geo` values\n",
    "    duplicate_geo = df[df.duplicated(subset=['.geo'], keep=False)]\n",
    "    \n",
    "    # Check if duplicates are identical or contain differing values\n",
    "    if not duplicate_geo.empty:\n",
    "        identical_duplicates = duplicate_geo[duplicate_geo.duplicated(keep='first')]\n",
    "        differing_duplicates = duplicate_geo.drop(identical_duplicates.index)\n",
    "        \n",
    "        print(f\"\\nFile: {file_name}\")\n",
    "        print(f\"Total duplicates: {len(duplicate_geo['.geo'].unique())}\")\n",
    "        print(f\"Identical duplicates: {len(identical_duplicates['.geo'].unique())}\")\n",
    "        print(f\"Differing duplicates: {len(differing_duplicates['.geo'].unique())}\")\n",
    "        \n",
    "        # Show sample of differing duplicates, if any\n",
    "        if not differing_duplicates.empty:\n",
    "            print(\"\\nSample of differing duplicate entries:\")\n",
    "            print(differing_duplicates.groupby('.geo').head())\n",
    "    else:\n",
    "        print(f\"\\nFile: {file_name} has no duplicates.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bb15e332-3a6c-439f-a0cd-bcbc4e88d9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in concatenated data: 214468\n",
      "Unique locations in concatenated data (after strict filtering): 10931\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Directory where the CSV files are located (all non-affected files were also copied to the filtered folder)\n",
    "csv_dir = '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/filtered'  # Adjust if needed\n",
    "\n",
    "# Load the standard set of locations from a correctly formatted file\n",
    "reference_file = '/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/quarterly_comps_indices/output_all_locations_2018_01.csv'\n",
    "reference_df = pd.read_csv(reference_file)\n",
    "reference_df['.geo'] = reference_df['.geo'].astype(str).str.strip()\n",
    "standard_locations = set(reference_df['.geo'].unique())\n",
    "\n",
    "# Function to extract the identifier from the filename\n",
    "def extract_identifier(filename):\n",
    "    base_name = os.path.basename(filename).replace('.csv', '')  # Remove the .csv extension\n",
    "    year = base_name.split('_')[-2]\n",
    "    month = int(base_name.split('_')[-1])  # Convert month directly to int\n",
    "    quarter = (month - 1) // 3 + 1  # Calculate the quarter\n",
    "    return f\"{year}_Q{quarter}\"\n",
    "\n",
    "# List to store each DataFrame\n",
    "df_list = []\n",
    "\n",
    "# Read each file, add the quarter identifier, and append to the list\n",
    "for file in glob.glob(os.path.join(csv_dir, '*.csv')):\n",
    "    df = pd.read_csv(file)\n",
    "    df['.geo'] = df['.geo'].astype(str).str.strip()  # Standardize `.geo` values\n",
    "    df['quarter'] = extract_identifier(file)\n",
    "    \n",
    "    # Filter to include only standard locations\n",
    "    df = df[df['.geo'].isin(standard_locations)]\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "final_df = pd.concat(df_list, axis=0, join='outer', ignore_index=True)\n",
    "\n",
    "# Check the shape and number of unique `.geo` entries after filtering\n",
    "print(f\"Total rows in concatenated data: {len(final_df)}\")\n",
    "print(f\"Unique locations in concatenated data (after strict filtering): {final_df['.geo'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d693c752-8b31-40ec-9b4b-219cfca8a49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated DataFrame:\n",
      "                                                .geo  NDVI_mean  NDVI_std  \\\n",
      "0  {\"type\":\"Point\",\"coordinates\":[-0.003159007999...   0.134840  0.054608   \n",
      "1  {\"type\":\"Point\",\"coordinates\":[-0.003219756,52...   0.239838  0.057186   \n",
      "2  {\"type\":\"Point\",\"coordinates\":[-0.004928459000...   0.233253  0.088611   \n",
      "3  {\"type\":\"Point\",\"coordinates\":[-0.006392204000...   0.295358  0.094453   \n",
      "4  {\"type\":\"Point\",\"coordinates\":[-0.011575600999...   0.234918  0.054999   \n",
      "\n",
      "   NDVI_trend  NDMI_mean  NDMI_std  NDMI_trend  BSI_mean   BSI_std  BSI_trend  \\\n",
      "0   -0.002187  -0.022124  0.048395   -0.002115  0.059456  0.032955   0.001738   \n",
      "1   -0.002217   0.132141  0.045441    0.001040 -0.063177  0.027550  -0.000641   \n",
      "2    0.000396   0.099711  0.069891    0.002635 -0.037607  0.056264  -0.002425   \n",
      "3    0.005872   0.186234  0.069075   -0.000386 -0.102043  0.048325  -0.000171   \n",
      "4   -0.002956   0.132636  0.035401   -0.000529 -0.059274  0.025155   0.000839   \n",
      "\n",
      "   SOCI_mean  SOCI_std    SOCI_trend  \n",
      "0   0.000059  0.000010 -5.068301e-07  \n",
      "1   0.000078  0.000015 -3.556697e-07  \n",
      "2   0.000079  0.000013 -4.581567e-07  \n",
      "3   0.000077  0.000013  8.747049e-07  \n",
      "4   0.000068  0.000009 -4.444866e-07  \n",
      "Missing values in the final aggregated DataFrame:\n",
      ".geo          0\n",
      "NDVI_mean     0\n",
      "NDVI_std      0\n",
      "NDVI_trend    0\n",
      "NDMI_mean     0\n",
      "NDMI_std      0\n",
      "NDMI_trend    0\n",
      "BSI_mean      0\n",
      "BSI_std       0\n",
      "BSI_trend     0\n",
      "SOCI_mean     0\n",
      "SOCI_std      0\n",
      "SOCI_trend    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#aggregate mean, std and trend\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Function to calculate trend across quarters\n",
    "def calculate_trend(series):\n",
    "    series = series.dropna()\n",
    "    if len(series) > 1:\n",
    "        x = range(len(series))\n",
    "        slope, _, _, _, _ = linregress(x, series)\n",
    "        return slope\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Group by location and calculate mean, std, and trend across quarters for each index\n",
    "grouped = final_df.groupby('.geo').agg({\n",
    "    'NDVI': ['mean', 'std', calculate_trend],\n",
    "    'NDMI': ['mean', 'std', calculate_trend],\n",
    "    'BSI': ['mean', 'std', calculate_trend],\n",
    "    'SOCI': ['mean', 'std', calculate_trend]\n",
    "})\n",
    "\n",
    "# Flatten multi-index columns for easier access\n",
    "grouped.columns = ['_'.join(col).replace('calculate_trend', 'trend') for col in grouped.columns.values]\n",
    "agg_df = grouped.reset_index()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(\"Aggregated DataFrame:\")\n",
    "print(agg_df.head())\n",
    "print(\"Missing values in the final aggregated DataFrame:\")\n",
    "print(agg_df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1c1515a0-adf0-4514-8836-10d9bb67ce08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.geo</th>\n",
       "      <th>NDVI_mean</th>\n",
       "      <th>NDVI_std</th>\n",
       "      <th>NDVI_trend</th>\n",
       "      <th>NDMI_mean</th>\n",
       "      <th>NDMI_std</th>\n",
       "      <th>NDMI_trend</th>\n",
       "      <th>BSI_mean</th>\n",
       "      <th>BSI_std</th>\n",
       "      <th>BSI_trend</th>\n",
       "      <th>SOCI_mean</th>\n",
       "      <th>SOCI_std</th>\n",
       "      <th>SOCI_trend</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-0.003159007999...</td>\n",
       "      <td>0.134840</td>\n",
       "      <td>0.054608</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.022124</td>\n",
       "      <td>0.048395</td>\n",
       "      <td>-0.002115</td>\n",
       "      <td>0.059456</td>\n",
       "      <td>0.032955</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-5.068301e-07</td>\n",
       "      <td>41.411819</td>\n",
       "      <td>-0.003159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-0.003219756,52...</td>\n",
       "      <td>0.239838</td>\n",
       "      <td>0.057186</td>\n",
       "      <td>-0.002217</td>\n",
       "      <td>0.132141</td>\n",
       "      <td>0.045441</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>-0.063177</td>\n",
       "      <td>0.027550</td>\n",
       "      <td>-0.000641</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-3.556697e-07</td>\n",
       "      <td>52.751181</td>\n",
       "      <td>-0.003220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-0.004928459000...</td>\n",
       "      <td>0.233253</td>\n",
       "      <td>0.088611</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.099711</td>\n",
       "      <td>0.069891</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>-0.037607</td>\n",
       "      <td>0.056264</td>\n",
       "      <td>-0.002425</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-4.581567e-07</td>\n",
       "      <td>42.011973</td>\n",
       "      <td>-0.004928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-0.006392204000...</td>\n",
       "      <td>0.295358</td>\n",
       "      <td>0.094453</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.186234</td>\n",
       "      <td>0.069075</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>-0.102043</td>\n",
       "      <td>0.048325</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>8.747049e-07</td>\n",
       "      <td>47.966599</td>\n",
       "      <td>-0.006392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-0.011575600999...</td>\n",
       "      <td>0.234918</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>-0.002956</td>\n",
       "      <td>0.132636</td>\n",
       "      <td>0.035401</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>-0.059274</td>\n",
       "      <td>0.025155</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-4.444866e-07</td>\n",
       "      <td>43.792581</td>\n",
       "      <td>-0.011576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10926</th>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[9.984522829,54....</td>\n",
       "      <td>0.271837</td>\n",
       "      <td>0.117279</td>\n",
       "      <td>0.006997</td>\n",
       "      <td>0.206005</td>\n",
       "      <td>0.071890</td>\n",
       "      <td>-0.001006</td>\n",
       "      <td>-0.109503</td>\n",
       "      <td>0.031705</td>\n",
       "      <td>-0.001009</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>9.487893e-07</td>\n",
       "      <td>54.624020</td>\n",
       "      <td>9.984523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10927</th>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[9.985930727,50....</td>\n",
       "      <td>0.208370</td>\n",
       "      <td>0.102867</td>\n",
       "      <td>-0.002781</td>\n",
       "      <td>0.174325</td>\n",
       "      <td>0.076662</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>-0.080351</td>\n",
       "      <td>0.046170</td>\n",
       "      <td>-0.002301</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-9.973288e-07</td>\n",
       "      <td>50.417982</td>\n",
       "      <td>9.985931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10928</th>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[9.9866519580000...</td>\n",
       "      <td>0.313676</td>\n",
       "      <td>0.129995</td>\n",
       "      <td>-0.002506</td>\n",
       "      <td>0.232764</td>\n",
       "      <td>0.048592</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.139178</td>\n",
       "      <td>0.026784</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-2.862957e-07</td>\n",
       "      <td>47.827606</td>\n",
       "      <td>9.986652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10929</th>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[9.986707895,47....</td>\n",
       "      <td>0.295762</td>\n",
       "      <td>0.132434</td>\n",
       "      <td>-0.000806</td>\n",
       "      <td>0.245628</td>\n",
       "      <td>0.067698</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>-0.138162</td>\n",
       "      <td>0.025542</td>\n",
       "      <td>-0.000944</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-3.367315e-07</td>\n",
       "      <td>47.611616</td>\n",
       "      <td>9.986708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10930</th>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[9.9872981670000...</td>\n",
       "      <td>0.254147</td>\n",
       "      <td>0.091357</td>\n",
       "      <td>-0.003245</td>\n",
       "      <td>0.134796</td>\n",
       "      <td>0.051709</td>\n",
       "      <td>-0.002013</td>\n",
       "      <td>-0.063935</td>\n",
       "      <td>0.041592</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-7.481201e-07</td>\n",
       "      <td>45.179970</td>\n",
       "      <td>9.987298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10931 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    .geo  NDVI_mean  NDVI_std  \\\n",
       "0      {\"type\":\"Point\",\"coordinates\":[-0.003159007999...   0.134840  0.054608   \n",
       "1      {\"type\":\"Point\",\"coordinates\":[-0.003219756,52...   0.239838  0.057186   \n",
       "2      {\"type\":\"Point\",\"coordinates\":[-0.004928459000...   0.233253  0.088611   \n",
       "3      {\"type\":\"Point\",\"coordinates\":[-0.006392204000...   0.295358  0.094453   \n",
       "4      {\"type\":\"Point\",\"coordinates\":[-0.011575600999...   0.234918  0.054999   \n",
       "...                                                  ...        ...       ...   \n",
       "10926  {\"type\":\"Point\",\"coordinates\":[9.984522829,54....   0.271837  0.117279   \n",
       "10927  {\"type\":\"Point\",\"coordinates\":[9.985930727,50....   0.208370  0.102867   \n",
       "10928  {\"type\":\"Point\",\"coordinates\":[9.9866519580000...   0.313676  0.129995   \n",
       "10929  {\"type\":\"Point\",\"coordinates\":[9.986707895,47....   0.295762  0.132434   \n",
       "10930  {\"type\":\"Point\",\"coordinates\":[9.9872981670000...   0.254147  0.091357   \n",
       "\n",
       "       NDVI_trend  NDMI_mean  NDMI_std  NDMI_trend  BSI_mean   BSI_std  \\\n",
       "0       -0.002187  -0.022124  0.048395   -0.002115  0.059456  0.032955   \n",
       "1       -0.002217   0.132141  0.045441    0.001040 -0.063177  0.027550   \n",
       "2        0.000396   0.099711  0.069891    0.002635 -0.037607  0.056264   \n",
       "3        0.005872   0.186234  0.069075   -0.000386 -0.102043  0.048325   \n",
       "4       -0.002956   0.132636  0.035401   -0.000529 -0.059274  0.025155   \n",
       "...           ...        ...       ...         ...       ...       ...   \n",
       "10926    0.006997   0.206005  0.071890   -0.001006 -0.109503  0.031705   \n",
       "10927   -0.002781   0.174325  0.076662    0.003807 -0.080351  0.046170   \n",
       "10928   -0.002506   0.232764  0.048592    0.000028 -0.139178  0.026784   \n",
       "10929   -0.000806   0.245628  0.067698    0.001888 -0.138162  0.025542   \n",
       "10930   -0.003245   0.134796  0.051709   -0.002013 -0.063935  0.041592   \n",
       "\n",
       "       BSI_trend  SOCI_mean  SOCI_std    SOCI_trend        lat      long  \n",
       "0       0.001738   0.000059  0.000010 -5.068301e-07  41.411819 -0.003159  \n",
       "1      -0.000641   0.000078  0.000015 -3.556697e-07  52.751181 -0.003220  \n",
       "2      -0.002425   0.000079  0.000013 -4.581567e-07  42.011973 -0.004928  \n",
       "3      -0.000171   0.000077  0.000013  8.747049e-07  47.966599 -0.006392  \n",
       "4       0.000839   0.000068  0.000009 -4.444866e-07  43.792581 -0.011576  \n",
       "...          ...        ...       ...           ...        ...       ...  \n",
       "10926  -0.001009   0.000074  0.000019  9.487893e-07  54.624020  9.984523  \n",
       "10927  -0.002301   0.000064  0.000022 -9.973288e-07  50.417982  9.985931  \n",
       "10928   0.000284   0.000076  0.000017 -2.862957e-07  47.827606  9.986652  \n",
       "10929  -0.000944   0.000074  0.000018 -3.367315e-07  47.611616  9.986708  \n",
       "10930   0.001665   0.000075  0.000014 -7.481201e-07  45.179970  9.987298  \n",
       "\n",
       "[10931 rows x 15 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract latitude and longitude from GeoJSON data\n",
    "def extract_lat_long(geo_json_str):\n",
    "    try:\n",
    "        geo_data = json.loads(geo_json_str)\n",
    "        # Assuming GeoJSON is of type Point: {\"type\": \"Point\", \"coordinates\": [longitude, latitude]}\n",
    "        if geo_data['type'] == 'Point':\n",
    "            longitude, latitude = geo_data['coordinates']\n",
    "            return latitude, longitude\n",
    "        else:\n",
    "            return None, None  # In case it’s not a Point type\n",
    "    except (json.JSONDecodeError, KeyError, TypeError):\n",
    "        return None, None  # In case of any parsing issues\n",
    "\n",
    "# Apply the function to extract lat and long and create new columns in agg_df\n",
    "agg_df['lat'], agg_df['long'] = zip(*agg_df['.geo'].apply(extract_lat_long))\n",
    "\n",
    "agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ae426333-efd2-4a6c-a161-e9aa2809a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "del agg_df['.geo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "52a1c476-dbe7-4f38-8638-206f361ba57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>.geo</th>\n",
       "      <th>NDVI_mean</th>\n",
       "      <th>NDVI_std</th>\n",
       "      <th>NDVI_trend</th>\n",
       "      <th>NDMI_mean</th>\n",
       "      <th>NDMI_std</th>\n",
       "      <th>NDMI_trend</th>\n",
       "      <th>BSI_mean</th>\n",
       "      <th>BSI_std</th>\n",
       "      <th>BSI_trend</th>\n",
       "      <th>SOCI_mean</th>\n",
       "      <th>SOCI_std</th>\n",
       "      <th>SOCI_trend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.411819</td>\n",
       "      <td>-0.003159</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-0.003159007999...</td>\n",
       "      <td>0.134840</td>\n",
       "      <td>0.054608</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.022124</td>\n",
       "      <td>0.048395</td>\n",
       "      <td>-0.002115</td>\n",
       "      <td>0.059456</td>\n",
       "      <td>0.032955</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-5.068301e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.751181</td>\n",
       "      <td>-0.003220</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-0.003219756,52...</td>\n",
       "      <td>0.239838</td>\n",
       "      <td>0.057186</td>\n",
       "      <td>-0.002217</td>\n",
       "      <td>0.132141</td>\n",
       "      <td>0.045441</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>-0.063177</td>\n",
       "      <td>0.027550</td>\n",
       "      <td>-0.000641</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-3.556697e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.011973</td>\n",
       "      <td>-0.004928</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-0.004928459000...</td>\n",
       "      <td>0.233253</td>\n",
       "      <td>0.088611</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.099711</td>\n",
       "      <td>0.069891</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>-0.037607</td>\n",
       "      <td>0.056264</td>\n",
       "      <td>-0.002425</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-4.581567e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.966599</td>\n",
       "      <td>-0.006392</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-0.006392204000...</td>\n",
       "      <td>0.295358</td>\n",
       "      <td>0.094453</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.186234</td>\n",
       "      <td>0.069075</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>-0.102043</td>\n",
       "      <td>0.048325</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>8.747049e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.792581</td>\n",
       "      <td>-0.011576</td>\n",
       "      <td>{\"type\":\"Point\",\"coordinates\":[-0.011575600999...</td>\n",
       "      <td>0.234918</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>-0.002956</td>\n",
       "      <td>0.132636</td>\n",
       "      <td>0.035401</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>-0.059274</td>\n",
       "      <td>0.025155</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-4.444866e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lat      long  \\\n",
       "loc_id                        \n",
       "0       41.411819 -0.003159   \n",
       "1       52.751181 -0.003220   \n",
       "2       42.011973 -0.004928   \n",
       "3       47.966599 -0.006392   \n",
       "4       43.792581 -0.011576   \n",
       "\n",
       "                                                     .geo  NDVI_mean  \\\n",
       "loc_id                                                                 \n",
       "0       {\"type\":\"Point\",\"coordinates\":[-0.003159007999...   0.134840   \n",
       "1       {\"type\":\"Point\",\"coordinates\":[-0.003219756,52...   0.239838   \n",
       "2       {\"type\":\"Point\",\"coordinates\":[-0.004928459000...   0.233253   \n",
       "3       {\"type\":\"Point\",\"coordinates\":[-0.006392204000...   0.295358   \n",
       "4       {\"type\":\"Point\",\"coordinates\":[-0.011575600999...   0.234918   \n",
       "\n",
       "        NDVI_std  NDVI_trend  NDMI_mean  NDMI_std  NDMI_trend  BSI_mean  \\\n",
       "loc_id                                                                    \n",
       "0       0.054608   -0.002187  -0.022124  0.048395   -0.002115  0.059456   \n",
       "1       0.057186   -0.002217   0.132141  0.045441    0.001040 -0.063177   \n",
       "2       0.088611    0.000396   0.099711  0.069891    0.002635 -0.037607   \n",
       "3       0.094453    0.005872   0.186234  0.069075   -0.000386 -0.102043   \n",
       "4       0.054999   -0.002956   0.132636  0.035401   -0.000529 -0.059274   \n",
       "\n",
       "         BSI_std  BSI_trend  SOCI_mean  SOCI_std    SOCI_trend  \n",
       "loc_id                                                          \n",
       "0       0.032955   0.001738   0.000059  0.000010 -5.068301e-07  \n",
       "1       0.027550  -0.000641   0.000078  0.000015 -3.556697e-07  \n",
       "2       0.056264  -0.002425   0.000079  0.000013 -4.581567e-07  \n",
       "3       0.048325  -0.000171   0.000077  0.000013  8.747049e-07  \n",
       "4       0.025155   0.000839   0.000068  0.000009 -4.444866e-07  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the index and drop the old index (this creates a default integer index)\n",
    "agg_df = agg_df.reset_index(drop=True)\n",
    "\n",
    "# Add `loc_id` column based on the current index\n",
    "agg_df['loc_id'] = agg_df.index\n",
    "\n",
    "# Set `loc_id` as the index\n",
    "agg_df = agg_df.set_index('loc_id')\n",
    "\n",
    "# Reorder columns to place `lat`, `long` at the front\n",
    "columns_order = ['lat', 'long'] + [col for col in agg_df.columns if col not in ['lat', 'long']]\n",
    "agg_df = agg_df[columns_order]\n",
    "\n",
    "# Verify the structure\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1cc51f04-03d3-48f5-8cc9-147a92bb1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final dataframe to a CSV file\n",
    "agg_df.to_csv('/Users/maxsonntag/Documents/GitHub/SOC_predictor/data/satellite_data/landsat_indices_agged.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
